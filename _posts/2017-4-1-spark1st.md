---
layout: post
title: Spark 개념잡기
---
회사는 환경이 모두 갖추어져 있으므로 Spark sql에 집중하면 된다.
Spark은 셔플 이라는 작업을 할 때 narrow dependancy를 잘 사용한다.
Spark은 iteration을 할 때 메모리에 중간 작업을 적재한다.
Spark은 Dataframe을 캐쉬해 두면 필요한 컬럼에만 접근하도록 할 수 있다.
Spark은 action이 실행되기 전에는 lineage만 기록된다. 즉 캐싱 같은 거는 실제 나중에 일어난다.(lazy)
Spark은 쿼리를 빨리 돌리는 것이 아니라 셔플 최적화와 스테이지간 자료 공유를 Ram에서 하기 때문에
분산 처리가 빨라진다. 이걸 이용해서 쿼리를 돌려야 빨라진다.
